# Example environment variables for D-Model-Runner
# Copy this file to .env and modify as needed

# API Configuration
DMR_BASE_URL=http://localhost:12434/engines/llama.cpp/v1/
DMR_API_KEY=anything
DMR_DEFAULT_MODEL=ai/gemma3

# Model Parameters
DMR_MAX_TOKENS=500
DMR_TEMPERATURE=0.7

# Logging
DMR_DEBUG=false
DMR_LOG_LEVEL=INFO

# Alternative Docker Model Runner URLs (uncomment as needed)
# DMR_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/
# DMR_BASE_URL=unix:///var/run/docker.sock/engines/llama.cpp/v1/